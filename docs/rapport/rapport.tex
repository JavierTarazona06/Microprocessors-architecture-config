\documentclass[conference]{IEEEtran}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{url}

\begin{document}

\title{
    Test Microprocessors Architecture Configuration }

\author{
    \begin{tabular}{@{}c c c@{}}
        \begin{minipage}[t]{0.29\textwidth}
            \centering
            \textbf{Javier Andres Tarazona Jimenez}\\
            \textit{Ingénieur Degree Programme STIC}\\
            \textit{ENSTA Paris}\\
            Paris, France\\
            \url{javier-andres.tarazona@ensta-paris.fr}
        \end{minipage}
        &
        \begin{minipage}[t]{0.29\textwidth}
            \centering
            \textbf{Jair Anderson Vasquez Torres}\\
            \textit{Ingénieur Degree Programme STIC}\\
            \textit{ENSTA Paris}\\
            Paris, France\\
            \url{jair-anderson.vasquez@ensta-paris.fr}
        \end{minipage}
        &
        \begin{minipage}[t]{0.29\textwidth}
            \centering
            \textbf{Maeva Noukoua}\\
            \textit{Ingénieur Degree Programme STIC}\\
            \textit{ENSTA Paris}\\
            Paris, France\\
            \url{maeva-sandy.noukoua@ensta-paris.fr}
        \end{minipage}
        \\[1.2em]
        \multicolumn{3}{c}{
            \begin{minipage}[t]{0.29\textwidth}
                \centering
                \textbf{Carlos}\\
                \textit{Ingénieur Degree Programme STIC}\\
                \textit{ENSTA Paris}\\
                Paris, France\\
                \url{carlos@ensta-paris.fr}
            \end{minipage}
        }
    \end{tabular}
}

\maketitle

\begin{abstract}
...
\end{abstract}

\begin{IEEEkeywords}
...
\end{IEEEkeywords}

%Examples
%\input{sections/descriptors_pairing.tex}

%\input{sections/detectors.tex}

\section{Exercice 4 --- Profiling (Q1)}
\paragraph{Objectif.}
Le \emph{profiling} de l'\emph{instruction mix} consiste à mesurer la répartition des instructions exécutées par grandes catégories
(calcul entier, mémoire, contrôle, etc.). Cette information est essentielle en architecture : elle permet d'identifier
\emph{où se situe la pression dominante} (unités de calcul, hiérarchie mémoire, prédiction de branchements), et donc
d'anticiper quels leviers microarchitecturaux sont les plus pertinents.

\paragraph{Méthode.}
Nous avons simulé les exécutions avec gem5 en mode SE (ISA RISC-V), en configuration de type A7 (\texttt{se\_A7.py}).
Les compteurs proviennent des instructions \emph{committed} (retired). Le nombre total d'instructions exécutées est
\(N = \texttt{simInsts}\).
Pour chaque catégorie \(c\), on note \(I_c\) le nombre d'instructions appartenant à \(c\). Le pourcentage associé est :
\[
\mathrm{pct}(c) = 100 \times \frac{I_c}{N}.
\]
Les valeurs sont arrondies à deux décimales (somme \(\approx 100\%\)).

\paragraph{Résultats détaillés.}
\begin{table}[h]
\centering
\scriptsize
\caption{Répartition des instructions exécutées (profiling) --- configuration A7.}
\label{tab:ex4_q1_profiling}
\begin{tabular}{|l|r|r|r|r|}
\hline
\textbf{Catégorie} & \multicolumn{2}{c|}{\textbf{Dijkstra (A7)}} & \multicolumn{2}{c|}{\textbf{Blowfish (A7)}} \\
\cline{2-5}
 & \textbf{Count} & \textbf{\%} & \textbf{Count} & \textbf{\%} \\
\hline
ALU entier & 22118141 & 44.09\% & 1882443 & 55.42\% \\
Chargements (Load) & 11799269 & 23.52\% & 771841 & 22.72\% \\
Stockages (Store) & 4853941 & 9.68\% & 408487 & 12.03\% \\
Branches (contrôle) & 9870255 & 19.67\% & 334128 & 9.84\% \\
Mult/Div entier & 1517371 & 3.02\% & 6 & 0.00\% \\
Flottant (FP) & 12 & 0.00\% & 12 & 0.00\% \\
Autres & 10476 & 0.02\% & 18 & 0.00\% \\
\hline
\textbf{TOTAL} (\(\texttt{simInsts}\)) & \textbf{50169465} & \textbf{100.00\%} & \textbf{3396935} & \textbf{100.00\%} \\
\hline
\end{tabular}
\end{table}

\paragraph{Synthèse par familles (lecture plus “architecture”).}
Afin de mieux comparer les pressions microarchitecturales, on regroupe les catégories en trois familles :
\emph{calcul entier} (ALU + Mult/Div), \emph{mémoire} (Load + Store) et \emph{contrôle} (Branches).

\begin{table}[h]
\centering
\scriptsize
\caption{Agrégation par familles : calcul, mémoire et contrôle (A7).}
\label{tab:ex4_q1_profiling_agg}
\begin{tabular}{|l|r|r|r|}
\hline
\textbf{Famille} & \textbf{Dijkstra (\%)} & \textbf{Blowfish (\%)} & \textbf{$\Delta$ (BF -- Dij) [points]} \\
\hline
Calcul entier (ALU + Mult/Div) & 47.11 & 55.42 & +8.31 \\
Mémoire (Load + Store) & 33.20 & 34.75 & +1.55 \\
Contrôle (Branches) & 19.67 & 9.84 & -9.83 \\
Reste (FP + Autres) & $\approx 0.02$ & $\approx 0.00$ & $\approx 0$ \\
\hline
\end{tabular}
\end{table}

\paragraph{Interprétation (comparaison chiffrée).}
Les deux applications présentent une part mémoire comparable (\(\approx 33.20\%\) pour Dijkstra contre \(\approx 34.75\%\) pour Blowfish),
ce qui indique que la hiérarchie mémoire (L1/L2) reste un levier important dans les deux cas.
En revanche, Dijkstra est nettement plus \emph{control-heavy} : les branches représentent \(19.67\%\) des instructions contre \(9.84\%\) pour Blowfish,
soit environ \(\times 2\) de densité de contrôle. À l'inverse, Blowfish est davantage \emph{compute-heavy} : la part d'ALU entier atteint \(55.42\%\)
contre \(44.09\%\) pour Dijkstra (+11.33 points). Les instructions FP sont négligeables (quelques occurrences attribuables à un surcoût du runtime plutôt
qu'au noyau algorithmique).


\subsection{Q2 : Catégorie à améliorer}

Sur \textbf{Dijkstra}, la part \textbf{contrôle} est élevée (\textbf{branches = 19.67\%}) et s’ajoute à une pression \textbf{mémoire} déjà importante (\textbf{load+store = 23.52\% + 9.68\% = 33.20\%}) : améliorer la \textbf{prédiction de branchements} (et réduire les bulles/flush) est donc un levier prioritaire pour ce code très \emph{branchy}.  
Sur \textbf{Blowfish}, le profil est surtout \textbf{compute-heavy} en entier (\textbf{ALU = 55.42\%} avec \textbf{branches = 9.84\%}) : l’amélioration la plus pertinente concerne le \textbf{débit/latence des opérations entières} (ALU), tandis que la mémoire reste secondaire bien que non négligeable (\textbf{load+store = 34.75\%}).  
Ainsi, la catégorie à optimiser dépend de l’application : \textbf{contrôle (branches) pour Dijkstra} et \textbf{calcul entier (ALU) pour Blowfish}.

\subsection{Q3 : Comparaison avec les charges du TP2 (SSCA2-BCS, SHA-1, poly\_mult)}

Pour comparer Dijkstra et Blowfish aux benchmarks du TP2, on s’appuie sur une lecture \emph{architecture} en trois familles :
(i) \textbf{calcul entier} (ALU + Mult/Div), (ii) \textbf{mémoire} (Load + Store) et (iii) \textbf{contrôle} (Branches).
Cette classification renseigne directement sur les ressources dominantes (unités entières, hiérarchie mémoire, prédiction de branchement)
et sur la sensibilité aux mécanismes OoO (ROB/LSQ) et au masquage de latence.

\paragraph{Dijkstra vs. SSCA2-BCS (graphes, accès irréguliers).}
Dijkstra présente une composante \textbf{contrôle} élevée (\textbf{19.67\%} de branches) ainsi qu’une pression \textbf{mémoire} marquée
(\textbf{Load+Store = 33.20\%}). Ce profil est typique d’un traitement de graphe : parcours, conditions dépendantes des données,
et accès non séquentiels (structures et indices variables), ce qui dégrade la localité et rend les préchargements moins efficaces.
On s’attend donc à des comportements proches de \textbf{SSCA2-BCS} (également orienté graphes) : forte sensibilité au front-end
(prédiction de branchement) et à la capacité du cœur OoO à tolérer des latences mémoire (fenêtres ROB/LSQ, MLP).

\paragraph{Blowfish vs. SHA-1 (noyaux compute-bound entiers).}
Blowfish est davantage \textbf{compute-heavy} en entier : \textbf{ALU+Mult/Div = 55.42\%}, avec un \textbf{contrôle plus faible}
(\textbf{9.84\%} de branches), tout en conservant une part mémoire non négligeable (\textbf{Load+Store = 34.75\%}) liée aux buffers et tables.
Cette dynamique se rapproche de \textbf{SHA-1}, qui est encore plus dominé par le calcul entier : dans notre run \emph{SHA small},
on obtient \textbf{78.34\%} d’ALU entier, \textbf{Load+Store = 16.29\%} et \textbf{5.37\%} de branches.
Ainsi, SHA-1 et Blowfish sont tous deux des noyaux à contrôle relativement réduit et à calcul entier majoritaire ; la différence principale
est que \textbf{SHA-1 est plus “pur compute”}, tandis que \textbf{Blowfish} conserve davantage d’accès mémoire (p.ex. tables/S-boxes), ce qui peut
augmenter la sensibilité aux caches lorsque les ensembles de données grandissent.

\paragraph{poly\_mult (produit de polynômes / convolution).}
À l’inverse des charges de type graphe, \textbf{poly\_mult} manipule généralement des tableaux et des boucles régulières :
les accès sont souvent \emph{séquentiels} (bonne localité spatiale), et la part de branches est typiquement faible (boucles simples).
On s’attend donc à un comportement plus proche d’un noyau \emph{streaming} : la performance dépend alors (i) du \textbf{débit de calcul}
(multiplications/additions) et (ii) de la \textbf{bande passante mémoire} lorsque les tableaux dépassent les caches.
En conséquence, lorsqu’on rend le cœur plus agressif (meilleur IPC théorique), la latence/bande passante mémoire tend à devenir un facteur
plus visible : l’optimisation de la hiérarchie mémoire (caches, miss rate effectif, éventuel préchargement) devient alors un levier majeur,
surtout pour les grandes tailles.

\paragraph{Synthèse.}
En résumé, \textbf{Dijkstra} se rapproche des workloads \emph{graph/irregular} comme \textbf{SSCA2-BCS} (contrôle + mémoire élevés),
alors que \textbf{Blowfish} se situe entre un noyau \emph{compute entier} et une charge mémoire modérée, et se compare naturellement à \textbf{SHA-1}
(mais avec plus d’accès mémoire). Enfin, \textbf{poly\_mult} est attendu plus régulier et potentiellement limité par la bande passante mémoire
sur grands tableaux, avec un contrôle faible.

% --- Tableau : Profiling SHA-1 (small) ---
\begin{table}[h]
\centering
\scriptsize
\caption{Répartition des instructions exécutées pour SHA-1 (\texttt{small}).}
\label{tab:tp2_sha_small_profiling}
\begin{tabular}{|l|r|r|}
\hline
\textbf{Catégorie} & \textbf{Count} & \textbf{\%} \\
\hline
ALU entier            & 10032072 & 78.34\% \\
Chargements (Load)    & 1496416  & 11.69\% \\
Stockages (Store)     & 589104   & 4.60\% \\
Branches (contrôle)   & 687432   & 5.37\% \\
Mult/Div entier       & 89       & 0.00\% \\
Flottant (FP)         & 12       & 0.00\% \\
Autres                & 55       & 0.00\% \\
\hline
\textbf{TOTAL}        & \textbf{12805180} & \textbf{100.00\%} \\
\hline
\end{tabular}
\end{table}

\subsection{Q11 : Efficacité énergétique}

\paragraph{Rappel méthodologique.}
L’efficacité énergétique est définie comme le rapport entre la performance obtenue (IPC) et la puissance consommée à fréquence maximale :

\[
\mathrm{Efficacité\ énergétique} = \frac{IPC}{P\ (mW)}.
\]

Les puissances maximales ont été déterminées à la question Q10 à partir des consommations en mW/MHz et des fréquences maximales.

\paragraph{Puissance maximale des processeurs.}

Pour le Cortex A7 :
\[
P_{A7} = 0.10\ \text{mW/MHz} \times 1000\ \text{MHz} = 100\ \text{mW}.
\]

Pour le Cortex A15 :
\[
P_{A15} = 0.20\ \text{mW/MHz} \times 2500\ \text{MHz} = 500\ \text{mW}.
\]

Ainsi :
\[
P_{A7} = 100\ \text{mW}, \quad P_{A15} = 500\ \text{mW}.
\]

\subsection*{Cortex A7}

\begin{table}[h]
\centering
\scriptsize
\caption{Efficacité énergétique du Cortex A7 en fonction de la taille du cache L1.}
\begin{tabular}{|c|c|c|}
\hline
\textbf{L1 (KB)} & \textbf{IPC} & \textbf{Efficacité énergétique} ($IPC/100$) \\
\hline
1  &  &  \\
2  &  &  \\
4  &  &  \\
8  &  &  \\
16 &  &  \\
\hline
\end{tabular}
\end{table}

\subsection*{Cortex A15}

\begin{table}[h]
\centering
\scriptsize
\caption{Efficacité énergétique du Cortex A15 en fonction de la taille du cache L1.}
\begin{tabular}{|c|c|c|}
\hline
\textbf{L1 (KB)} & \textbf{IPC} & \textbf{Efficacité énergétique} ($IPC/500$) \\
\hline
2  &  &  \\
4  &  &  \\
8  &  &  \\
16 &  &  \\
32 &  &  \\
\hline
\end{tabular}
\end{table}

\paragraph{Analyse qualitative attendue.}

L’efficacité énergétique augmente lorsque l’IPC augmente, c’est-à-dire lorsque la réduction des cache misses améliore l’utilisation des unités de calcul.

Cependant, malgré un IPC généralement plus élevé pour le Cortex A15, sa consommation énergétique est cinq fois supérieure à celle du Cortex A7 (500 mW contre 100 mW). Ainsi, l’amélioration d’IPC doit être suffisamment significative pour compenser ce surcoût énergétique.

On s’attend donc à observer :

\begin{itemize}
    \item Une amélioration de l’efficacité énergétique lorsque la taille du L1 augmente jusqu’à un point de saturation.
    \item Une stabilisation des gains au-delà d’une certaine taille de cache (rendements décroissants).
    \item Une efficacité énergétique globalement supérieure pour le Cortex A7, en raison de sa consommation nettement plus faible.
\end{itemize}

En conclusion, le Cortex A7 devrait offrir un meilleur compromis performance/énergie pour des charges modérées, tandis que le Cortex A15 privilégie la performance brute au détriment de la consommation.


\subsection{Q12: Architecture big.LITTLE}

\paragraph{Objectif.}
L’architecture big.LITTLE associe un cœur \emph{économe} (A7) et un cœur \emph{performant} (A15).
Pour chaque application, on souhaite proposer une configuration de caches L1 (\(I\text{-}L1\) et \(D\text{-}L1\) de même taille)
qui offre le meilleur compromis \emph{performance/énergie} à fréquence maximale, en s’appuyant sur les résultats des questions
Q10--Q11 \cite{TP4}.

\paragraph{Principe de décision (règle utilisée).}
Pour chaque processeur et chaque application, on retient :
\begin{itemize}
    \item la configuration de \(L1\) située au \emph{coude} des courbes (rendement décroissant), c.-à-d. la plus petite taille
    de \(L1\) à partir de laquelle l’IPC n’augmente plus significativement ;
    \item et/ou la configuration maximisant l’efficacité énergétique \(E = IPC/P\).
\end{itemize}
Cette stratégie reflète un choix “concepteur” : éviter d’augmenter \(L1\) lorsque le gain de performance devient marginal.

\subsection{Recommandation pour Dijkstra}

\paragraph{Cortex A7.}
D’après les résultats de Q11, l’efficacité énergétique de Dijkstra sur A7 est maximale (ou proche du maximum) pour
\(L1 = \textbf{[\,\underline{...}\,]}\,\mathrm{KB}\).
Au-delà, l’IPC progresse faiblement tandis que l’intérêt énergétique devient marginal.
Nous proposons donc :
\[
L1_{A7}^{(\mathrm{Dijkstra})} = \textbf{[\,\underline{...}\,]}\ \mathrm{KB}.
\]

\paragraph{Cortex A15.}
Sur A15, l’IPC est supérieur mais la consommation est plus élevée, ce qui réduit l’efficacité énergétique.
Les résultats montrent un coude / plateau à \(L1 = \textbf{[\,\underline{...}\,]}\,\mathrm{KB}\).
Nous proposons :
\[
L1_{A15}^{(\mathrm{Dijkstra})} = \textbf{[\,\underline{...}\,]}\ \mathrm{KB}.
\]

\paragraph{Synthèse Dijkstra.}
La configuration big.LITTLE recommandée pour Dijkstra est :
\[
(A7, A15) = (\textbf{[\,\underline{...}\,]}\ \mathrm{KB},\ \textbf{[\,\underline{...}\,]}\ \mathrm{KB}).
\]

\subsection{Recommandation pour Blowfish}

\paragraph{Cortex A7.}
Pour Blowfish, les résultats de Q11 indiquent que l’efficacité énergétique sur A7 est optimale (ou quasi optimale) pour
\(L1 = \textbf{[\,\underline{...}\,]}\,\mathrm{KB}\).
Nous proposons :
\[
L1_{A7}^{(\mathrm{Blowfish})} = \textbf{[\,\underline{...}\,]}\ \mathrm{KB}.
\]

\paragraph{Cortex A15.}
Pour A15, l’augmentation de \(L1\) améliore l’IPC jusqu’à \(L1 = \textbf{[\,\underline{...}\,]}\,\mathrm{KB}\), puis les gains deviennent faibles.
Au regard de l’efficacité énergétique, on retient :
\[
L1_{A15}^{(\mathrm{Blowfish})} = \textbf{[\,\underline{...}\,]}\ \mathrm{KB}.
\]

\paragraph{Synthèse Blowfish.}
La configuration big.LITTLE recommandée pour Blowfish est :
\[
(A7, A15) = (\textbf{[\,\underline{...}\,]}\ \mathrm{KB},\ \textbf{[\,\underline{...}\,]}\ \mathrm{KB}).
\]

\paragraph{Discussion générale.}
On s’attend à ce que le cœur A7 soit privilégié lorsque la contrainte énergétique domine (efficacité élevée),
tandis que le cœur A15 est mobilisé lorsque la performance brute est requise.
Les tailles retenues correspondent au meilleur compromis observé entre gain d’IPC et coût énergétique,
en évitant les configurations où l’augmentation de \(L1\) n’apporte plus de bénéfice notable.


\subsection{Q13 : Équivalence des configurations et compromis}

\paragraph{Comparaison des configurations optimales.}
Les tailles de cache L1 retenues pour Dijkstra et Blowfish ne sont pas nécessairement identiques.
Cette différence s’explique par la nature distincte des applications :
\begin{itemize}
    \item Dijkstra présente une pression importante sur le contrôle et la mémoire,
    \item Blowfish est davantage dominée par le calcul entier.
\end{itemize}

Ainsi, la taille optimale de L1 peut différer selon le profil microarchitectural de la charge.

\paragraph{Équivalence.}
Si les tailles optimales obtenues pour les deux applications sont différentes
(par exemple \(L1 = \textbf{[\,\underline{...}\,]}\,\mathrm{KB}\) pour Dijkstra et
\(L1 = \textbf{[\,\underline{...}\,]}\,\mathrm{KB}\) pour Blowfish),
alors les configurations ne sont pas strictement équivalentes.

En revanche, si les performances et l’efficacité énergétique restent proches
dans une même plage de tailles, on peut considérer les configurations comme quasi équivalentes.

\paragraph{Proposition de compromis.}
Dans un système réel, le cache L1 est fixe et ne peut être redimensionné dynamiquement.
Il est donc pertinent de choisir une taille offrant :
\begin{itemize}
    \item une performance proche de l’optimum pour les deux applications,
    \item une efficacité énergétique satisfaisante,
    \item un coût en surface raisonnable.
\end{itemize}

Nous proposons ainsi un compromis à
\(L1 = \textbf{[\,\underline{...}\,]}\,\mathrm{KB}\),
correspondant au meilleur équilibre global observé.

\paragraph{Conclusion sur les applications étudiées.}
Les résultats montrent que le dimensionnement optimal du cache dépend
fortement du profil applicatif.
Les applications orientées contrôle/mémoire bénéficient davantage
d’un L1 suffisamment dimensionné pour réduire les miss,
tandis que les charges compute-heavy sont plus sensibles
au débit des unités de calcul qu’à l’augmentation excessive du cache.


\subsection{Q14 : Approche méthodologique pour la spécification d’une architecture}

La conception d’une architecture destinée à exécuter plusieurs applications
dans un domaine spécifique doit suivre une approche systématique :

\begin{enumerate}
    \item \textbf{Profiling représentatif :}
    Identifier un ensemble d’applications représentatives du domaine
    et mesurer leur instruction mix ainsi que leurs métriques de performance.

    \item \textbf{Identification des pressions dominantes :}
    Déterminer si les charges sont principalement
    compute-bound, memory-bound ou control-bound.

    \item \textbf{Exploration paramétrique :}
    Faire varier les paramètres microarchitecturaux clés
    (taille des caches, largeur pipeline, prédiction de branchement, etc.)
    afin d’observer leur impact sur les métriques de performance,
    d’énergie et de surface.

    \item \textbf{Analyse multi-critères :}
    Évaluer les compromis performance/énergie/surface
    à l’aide d’indicateurs normalisés (IPC, efficacité énergétique,
    efficacité surfacique).

    \item \textbf{Choix robuste :}
    Sélectionner une configuration offrant des performances stables
    sur l’ensemble des applications,
    même si elle n’est pas optimale pour chacune individuellement.
\end{enumerate}

Cette approche permet de concevoir une architecture équilibrée,
robuste et adaptée au domaine cible,
plutôt qu’optimisée pour un cas particulier.


\begin{thebibliography}{00}

%TODO Delete this and add the real references of the project
\bibitem{opencv_feature_description}
A. Huam\'an, ``Feature Description,'' \emph{OpenCV Documentation} (OpenCV 4.14.0-pre), accessed Feb. 6, 2026. [Online]. Available: \url{https://docs.opencv.org/4.x/d5/dde/tutorial_feature_description.html}

\end{thebibliography}

\end{document}
